{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698bcc0-2ffa-4874-bae7-c33a001b5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f911a85-a89c-40a6-a333-433f99849ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseProblem(url:str, driver, dest_dir)->dict:\n",
    "    problem = dict()\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.execute_script('document.querySelector(\"div.pd-question-content input\").click()')\n",
    "    time.sleep(2)\n",
    "    page_source = driver.page_source\n",
    "    try:\n",
    "        soup = bs4.BeautifulSoup(page_source, \"lxml\")\n",
    "        correct_ans = [i[\"value\"] for i in soup.select(\"div.correct.pd-answer-text-finish input\")]\n",
    "        entry_title = soup.select(\"h1.entry-title\")[0].text\n",
    "        question_content = soup.select(\"div.question-content-wrapper img\")\n",
    "        question_img_paths = []\n",
    "        for i in question_content:\n",
    "            img_path = i[\"src\"].split(\"/\")[-1]\n",
    "            question_img_paths.append(img_path)\n",
    "            with open(os.path.join(dest_dir, img_path), \"wb\") as f:\n",
    "                f.write(requests.get(i[\"src\"]).content)\n",
    "        options = []\n",
    "        for i in soup.select(\"div.pd-question-content input\"):\n",
    "            option = i[\"value\"]\n",
    "            option_imgs_soup = bs4.BeautifulSoup(option, \"lxml\")\n",
    "            option_imgs = option_imgs_soup.select(\"img\")\n",
    "            if (option_imgs) :\n",
    "                for option_img in option_imgs:\n",
    "                    option_img_url = option_img[\"src\"]\n",
    "                    img_name = option_img_url.split(\"/\")[-1]\n",
    "                    option = f\"@{img_name}\"\n",
    "                    with open(img_name, \"wb\") as k:\n",
    "                        k.write(requests.get(option_img_url).content)\n",
    "            \n",
    "            options.append(option)\n",
    "\n",
    "\n",
    "        for el in soup.select(\"div.pd-answ-explanation p\"):\n",
    "            if re.compile(r'^\\s*references\\s*:', re.IGNORECASE).match(el.text) is not None:\n",
    "                references = re.sub(r\"^\\s*references\\s*:\\s*(.*)\", r\"\\1\", el.text, 0, re.MULTILINE | re.IGNORECASE)\n",
    "                problem['references'] = references\n",
    "            elif re.compile(r'^\\s*category\\s*:', re.IGNORECASE).match(el.text) is not None:\n",
    "                category = re.sub(r\"^\\s*category\\s*:\\s*(.*)\", r\"\\1\", el.text, 0, re.MULTILINE | re.IGNORECASE)\n",
    "                problem['category'] = category\n",
    "            elif re.compile(r'^\\s*explanation\\s*:', re.IGNORECASE).match(el.text) is not None:\n",
    "                explanation = re.sub(r\"^\\s*explanation\\s*:\\s*(.*)\", r\"\\1\", el.text, 0, re.MULTILINE | re.IGNORECASE)\n",
    "                problem['explanation'] = explanation\n",
    "                \n",
    "        problem[\"entry_title\"] = entry_title\n",
    "        problem[\"question_img_paths\"] = question_img_paths\n",
    "        problem[\"correct_ans\"] = correct_ans\n",
    "        problem[\"options\"] = options\n",
    "    except:\n",
    "        print(\"entry_title: \", entry_title)\n",
    "        print(\"question_img_paths: \", question_img_paths)\n",
    "        print(\"correct_ans: \", correct_ans)\n",
    "        print(\"options: \", options)\n",
    "        print(\"explanation: \", explanation)\n",
    "        print(\"references: \", references)\n",
    "        print(\"category: \", category)\n",
    "        driver.close()\n",
    "    return problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8412108-0141-42d2-8ce7-df5d415d61c4",
   "metadata": {},
   "source": [
    "## Scrape all question urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802b568-a76f-40ba-8417-9fa47d3d7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_bank_urls = [\"https://theorytest.org.uk/question-sitemap1.xml\",\n",
    "                \"https://theorytest.org.uk/question-sitemap2.xml\",\n",
    "                \"https://theorytest.org.uk/question-sitemap3.xml\",\n",
    "                \"https://theorytest.org.uk/question-sitemap4.xml\",\n",
    "                \"https://theorytest.org.uk/question-sitemap5.xml\",\n",
    "                \"https://theorytest.org.uk/question-sitemap6.xml\",\n",
    "                \"https://theorytest.org.uk/question-sitemap7.xml\",\n",
    "                \"https://theorytest.org.uk/question-sitemap8.xml\",\n",
    "                \"https://theorytest.org.uk/question-sitemap9.xml\",]\n",
    "\n",
    "def is_img(text):\n",
    "    pattern = re.compile(r\".*\\.(jpg|png|gif)$\")\n",
    "    if re.match(pattern, text):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "with open(\"question_urls.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    question_urls = []\n",
    "    for question_bank_url in question_bank_urls:\n",
    "        page = requests.get(question_bank_url).text\n",
    "        soup = bs4.BeautifulSoup(page, \"xml\")\n",
    "        for i in soup.find_all(\"loc\"):\n",
    "            question_url = i.text\n",
    "            if is_img(question_url):\n",
    "                continue\n",
    "            question_urls.append(question_url)\n",
    "    f.write(\"\\n\".join(question_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a89095-03de-456e-b3b9-aa7fcddbbba3",
   "metadata": {},
   "source": [
    "## Scrape question from each question url and save it individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765e63a-1b33-4da1-bcca-61b885ccb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver_options = Options()\n",
    "# driver_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox()\n",
    "dest_dir = \"./data\"\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "with open(\"question_urls.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for question_url in f.readlines():\n",
    "        print(question_url)\n",
    "        problem = parseProblem(question_url, driver, dest_dir)\n",
    "        time.sleep(2)\n",
    "        print(problem)\n",
    "        filename = os.path.join(dest_dir, f\"{question_url.rstrip(\"/\").split(\"/\")[-2]}.json\")\n",
    "        print(filename)\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(problem, f)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e5994-474b-4004-8543-a58ba75eeca3",
   "metadata": {},
   "source": [
    "## Assemble all questions into one single JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "493adc2d-55e4-447a-b858-229b01c4160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = \"data.json\"\n",
    "data = []\n",
    "for fname in os.listdir(dest_dir):\n",
    "    fpath = os.path.join(dest_dir, fname)\n",
    "    with open(fpath, 'r') as f:\n",
    "        if (fpath.endswith(\"json\")):\n",
    "            try:\n",
    "                data.append(json.load(f))\n",
    "            except:\n",
    "                print(fpath)\n",
    "with open(output_json, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca195c-c406-4ac8-acf7-2941485b905b",
   "metadata": {},
   "source": [
    "## Remove individual JSON files (make sure all data have been obtained before doing this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0739c55-e937-4252-b42a-80c45e224b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(dest_dir):\n",
    "    if (fname.endswith(\"json\")):\n",
    "        fpath = os.path.join(dest_dir, fname)\n",
    "        os.unlink(fpath)\n",
    "    \n",
    "os.rename(output_json, os.path.join(dest_dir, output_json))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
